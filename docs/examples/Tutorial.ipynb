{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485cce99-9f0e-4a6e-b53f-238070853c52",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "In this tutorial we creating a database using two custum databases:\n",
    "- raw data store: InMemoryCSVDB\n",
    "- rdf data store: InMemoryRDFDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d581c24-aad6-464e-9821-4e3da7259e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gldb[tutorial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646e194-b8fc-43f8-a5ef-52eaf5a82cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gldb import RawDataStore, RDFStore, GenericLinkedDatabase\n",
    "from gldb.stores import DataStoreManager\n",
    "from gldb.query import Query\n",
    "from gldb.query.rdfstorequery import SparqlQuery\n",
    "\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import rdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad33aff-c339-43cb-8880-7ff037883801",
   "metadata": {},
   "source": [
    "## Data Stores\n",
    "\n",
    "The concept defines **data stores** which are interfaces to databases. They can be RDF databases or traditional databases like SQL or noSQL databases.\n",
    "\n",
    "Let's first implement a concrete implementation for both types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69ad07-bea7-470a-a093-e46f427b4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDatabase(RawDataStore):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._filenames = []\n",
    "        self.tables = {}\n",
    "        self._expected_file_extensions = {\".csv\", }\n",
    "\n",
    "    @property\n",
    "    def expected_file_extensions(self):\n",
    "        return self._expected_file_extensions\n",
    "\n",
    "    def upload_file(self, filename: pathlib.Path) -> bool:\n",
    "        if filename.resolve().absolute() in self._filenames:\n",
    "            return True\n",
    "        self._filenames.append(filename.resolve().absolute())\n",
    "        self.tables[filename.stem] = pd.read_csv(filename)\n",
    "        return True\n",
    "\n",
    "    def execute_query(self, query: Query):\n",
    "        return query.execute(self.tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c302f7a-3be2-4e23-bdaa-2f1cace888ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryRDFDatabase(RDFStore):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._filenames = []\n",
    "        self._graphs = {}\n",
    "        self._expected_file_extensions = {\".ttl\", \".rdf\", \".jsonld\"}\n",
    "\n",
    "    @property\n",
    "    def expected_file_extensions(self):\n",
    "        return self._expected_file_extensions\n",
    "\n",
    "    def execute_query(self, query: SparqlQuery):\n",
    "        return query.execute(self.graph)\n",
    "\n",
    "    def upload_file(self, filename: pathlib.Path) -> bool:\n",
    "        self._filenames.append(filename.resolve().absolute())\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def graph(self) -> rdflib.Graph:\n",
    "        combined_graph = rdflib.Graph()\n",
    "        for filename in self._filenames:\n",
    "            g = self._graphs.get(filename, None)\n",
    "            if not g:\n",
    "                g = rdflib.Graph()\n",
    "                g.parse(filename)\n",
    "                for s, p, o in g:\n",
    "                    if isinstance(s, rdflib.BNode):\n",
    "                        new_s = rdflib.URIRef(f\"https://example.org/{s}\")\n",
    "                    else:\n",
    "                        new_s = s\n",
    "                    if isinstance(o, rdflib.BNode):\n",
    "                        new_o = rdflib.URIRef(f\"https://example.org/{o}\")\n",
    "                    else:\n",
    "                        new_o = o\n",
    "                    g.remove((s, p, o))\n",
    "                    g.add((new_s, p, new_o))\n",
    "                self._graphs[filename] = g\n",
    "            combined_graph += g\n",
    "        return combined_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9b830-82ee-4c58-9aae-cd1fbc9c9915",
   "metadata": {},
   "source": [
    "## Core\n",
    "\n",
    "The core implementation concerns the implementation of `GenericLinkedDatabase`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a10b5f-18f0-46f3-807b-9f3dd0e686cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericLinkedDatabaseImpl(GenericLinkedDatabase):\n",
    "\n",
    "    def __init__(self):\n",
    "        _store_manager = DataStoreManager()\n",
    "        _store_manager.add_store(\"rdf_database\", InMemoryRDFDatabase())\n",
    "        _store_manager.add_store(\"csv_database\", CSVDatabase())\n",
    "        self._store_manager = _store_manager\n",
    "\n",
    "    @property\n",
    "    def store_manager(self) -> DataStoreManager:\n",
    "        return self._store_manager\n",
    "        \n",
    "    def linked_upload(self, filename: Union[str, pathlib.Path]):\n",
    "        raise NotImplemented(\"linked_upload not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21978a-bb93-4e98-a0c0-9f9eeee32650",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "Now, let's instantiate the database and upload the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91012b-da42-496e-be11-81e1ec13bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GenericLinkedDatabaseImpl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e22f98-3868-404a-ad5a-671a225536e5",
   "metadata": {},
   "source": [
    "**Upload the semantic metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07e847-bb71-4d35-bb2f-8414c68519a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in pathlib.Path(\"data\").glob('*.jsonld'):\n",
    "    db[\"rdf_database\"].upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8d48c-82fc-4db7-aadc-b20a72d31b55",
   "metadata": {},
   "source": [
    "**Upload the raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af2751-a523-4a34-ae1b-76271366bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in pathlib.Path(\"data\").glob('*.csv'):\n",
    "    db[\"csv_database\"].upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488bffac-e4e6-498e-b74c-d14d2ee03262",
   "metadata": {},
   "source": [
    "### Query metadata\n",
    "\n",
    "Get all persons from the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e1f62-bfa7-49ad-bb1d-034a1bd5c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_all_persons = SparqlQuery(\"\"\"\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "SELECT * WHERE {\n",
    "    ?person a foaf:Person .\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a73c3f-edd6-4c41-b17a-523c8d951a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = db.execute_query(\"rdf_database\", select_all_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51fba9-0d18-4632-bdea-394bc46f9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.bindings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f12fc-004b-422f-86a7-0ad537b691aa",
   "metadata": {},
   "source": [
    "## Query data\n",
    "\n",
    "To query the CSV data, we first need to implement a query class `CSVQuery`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548af785-1bd5-4d39-aa96-9396226de197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVQuery(Query):\n",
    "\n",
    "    def __init__(self, table_name:str, query:str):\n",
    "        self.table_name = table_name\n",
    "        self.query = query\n",
    "\n",
    "    def execute(self, tables: List[pd.DataFrame]):\n",
    "        return tables[self.table_name].query(self.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cbfea-180f-41ff-bfcf-31787dc96cee",
   "metadata": {},
   "source": [
    "Find all values of column \"temperature\" above 23 in table \"temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65332568-bf1e-4c76-a54c-a66680af22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_above_23 = CSVQuery(table_name=\"temperature\",  query='temperature > 23.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d1faf-27a7-4c10-b7d7-dc65281dc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute_query(\"csv_database\", temperatures_above_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3214853-0090-4b68-8189-6e3d4492e45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
